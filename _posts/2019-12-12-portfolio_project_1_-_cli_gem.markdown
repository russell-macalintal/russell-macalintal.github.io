---
layout: post
title:      "Portfolio Project #1 - CLI Gem"
date:       2019-12-13 03:49:35 +0000
permalink:  portfolio_project_1_-_cli_gem
---


To be honest, the hardest part of this portfolio project for me was getting started. Writing the body of a code for an established test-driven development assignment where the environments and classes have already been set up is relatively easy. It is all guided work, after all, and it follows some pretty logical sequencing. Save for some syntax errors, I believe I have the basics of Object Oriented Ruby programming down (of course, I'm talking about only the most basic aspects; there is obviously still very much to learn about Ruby that'll come only with more hands-on experience and documentation research). However, setting up a project from scratch is an entirely different matter and something with which I had barely any prior practice. Not only did I find the prospect of setting up my own file system structure daunting, but couple that with having to make design decisions about how clients will interact with the program and how the code will interact with the website to be scraped and everything suddenly becomes quite overwhelming.

To alleviate the stress of starting my gem, I decided to jot down a very basic outline of the tasks I wanted to tackle as I went along. Although this was essentially a list of items I had already generated and stored in my head, writing them down and seeing them listed in front of me freed up the clutter in my mind and helped simplify each task and my approach. The next steps then involved revisiting lessons that introduced Git and Github, watching numerous Youtube videos about starting Ruby gems and setting up the correct repositories and project environments, and experimenting with several test and sample projects. After a somewhat tedious and agonizing start, I was finally able to get the ball rolling and my gem eventually took off.

The rest of the development process was pretty straightforward as I already had a roadmap of the specifications I wanted to implement and I was fairly confident in my ability to write an Object-Oriented Program. For this project, I decided to create a CLI that would gather information about the latest videogames and their corresponding critic reviews, sourced solely from the Gamespot.com website, and present all of that information to the user, in a simplistic and easy-to-read manner (with the help of the `colorize` gem). I am hoping to eventually expand on this code's capabilities and features in the future by having it source multiple gaming websites and aggregating and presenting that information in a muti-level CLI. I have always loved videogames and although I admittedly have not had as much time to invest in playing them, I still do enjoy reading and learning about them, oftentimes daydreaming about what it would be like to actually play them. So this seemed like a perfect program to tackle for my first portfolio project.

Although I was quick to establish the basic `CLI` class to interact with the user and `Game` class to store all the pertinent information, I faced a mild dilemma when it came to writing the `Scraper` class. For the purposes of this project, I decided that the `Scraper` class should consist mostly of class method definitions. Now, I'm aware of the most common anti-patterns that we have been recommended to avoid and although most of the sample projects I've seen delegates the creation of objects from scraped information to instance methods of the scraper class, I've decided to instead use the `Game` class to handle this responsbility. My reasoning for this is that the `Scraper` class is essentially used as a tool by the `Game` class only to gather information. Once this information is utilized by the `Game` class and stored as attributes within `Game` object instances, the scraped information held by the `Scraper` class is no longer needed. Therefore, it does not have to persist outside of the interim period in which it is scraped and then stored in a newly created `Game` object. As such, I did not believe it necessary to create an instance of the `Scraper` class to hold this information.

Outside of this design decision, which led to several refactors of multiple instance and class methods, the other items I had a bit of issue with were:
1. Getting the correct CSS selectors to isolate the data I wanted to gather. This took a bit of trial and error and is unfortunately entirely site-dependent, but after experimenting quite a bit with the webpage's HTML, I was finally able to isolate the correct and most efficient Nokogiri XML elements that contained the most useful information.
2. Optimizing the code, particularly the scraping methodology, in order to avoid long loading times. My initial scraping code worked to gather the complete set of information regarding each and every recent videogame reviewed. Needless to say, this led to initial set up times of roughly 2-3 minutes for a relatively short list of 100 videogames. In order to minimize wait times, I decided to only scrape the most basic information regarding the most recent videogame library and repeat a call to the `Scraper` class only once the user has selected a particular title to learn more about. This cut down the initial load times to mere seconds, rather than a magnitude of minutes. This optimization will become more apparent as the program is expanded to source more webpages and gather even more information.

Overall, I think this was a successful project open to future improvement, expansion, and collaboration.
Items for future improvement / expansion:
1. Expand the gem to scrape other gaming review websites.
2. Aggregate the scraped information from other websites and combine it with content from Gamespot.
3. Refactor the program to allow it to scrape larger amounts of data (ie. instead of the latest 100 games reviewed, scrape game reviews based on release year or console availability).
4. Allow the user to find and select games by title, console, genre, etc.
